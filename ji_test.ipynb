{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aaebaa1-874c-4946-ba55-dff62afdfe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOR üöÄ d2f547a torch 1.11.0+cu113 CUDA:0 (Tesla T4, 14971.875MB)\n",
      "\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3404320 parameters, 0 gradients, 12.6 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/data/2783/IMG20230927100144.jpg\n",
      "0.0030434131622314453\n",
      "0.04649853706359863\n",
      "tensor(56., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "{\n",
      "    \"algorithm_data\": {\n",
      "        \"is_alert\": false,\n",
      "        \"target_count\": 0,\n",
      "        \"target_info\": []\n",
      "    },\n",
      "    \"model_data\": {\n",
      "        \"objects\": [\n",
      "            {\n",
      "                \"x\": 11,\n",
      "                \"y\": 1128,\n",
      "                \"width\": 615,\n",
      "                \"height\": 610,\n",
      "                \"confidence\": 0.349609375\n",
      "            },\n",
      "            {\n",
      "                \"x\": 3706,\n",
      "                \"y\": 5,\n",
      "                \"width\": 268,\n",
      "                \"height\": 382,\n",
      "                \"confidence\": 0.333740234375\n",
      "            }\n",
      "        ],\n",
      "        \"mask\": \"mask_result.png\"\n",
      "    }\n",
      "}\n",
      "304.01746560299677\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "sys.path.insert(1, '/project/train/src_repo/yolov7/')\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "from utils.datasets import LoadStreams, LoadImages,letterbox\n",
    "from utils.general import set_logging\n",
    "from utils.plots import plot_one_box\n",
    "from ultralytics.yolo.utils.checks import check_imgsz, check_imshow\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "from ultralytics.yolo.utils import ops\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "# ####### ÂèÇÊï∞ËÆæÁΩÆ\n",
    "conf_thres = 0.24\n",
    "iou_thres = 0.2\n",
    "imgsz = 640\n",
    "weights = \"/project/train/src_repo/pretrain_model/yolov8n.pt\"\n",
    "weights_seg = \"/project/train/src_repo/pretrain_model/yolov8n-seg.pt\"\n",
    "device = '0'\n",
    "stride = 32\n",
    "names = ['dog', 'person', 'cat']\n",
    "names_seg = ['background', 'leash', 'dog']\n",
    "def init():\n",
    "    # Initialize\n",
    "    global imgsz, device, stride\n",
    "    set_logging()\n",
    "    device = select_device('0')\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = AutoBackend(weights, device=device, fp16=True)\n",
    "    model_seg = AutoBackend(weights_seg, device=device, fp16=True)\n",
    "    imgsz = check_imgsz(imgsz, stride=stride)  # check img_size\n",
    "    model.eval()\n",
    "    model_seg.eval()\n",
    "    # model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "    return model,model_seg\n",
    "\n",
    "def process_image(model, input_image=None, args=None, **kwargs):\n",
    "    # Padded resize\n",
    "    if args is not None:\n",
    "        cfg = json.loads(args)\n",
    "    t0 = time.time()\n",
    "    img0 = input_image\n",
    "    img = letterbox(img0, new_shape=imgsz, stride=stride, auto=True)[0]\n",
    "\n",
    "    # Convert\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # BGR to RGB, to 3x416x416\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.half()\n",
    "    #     img = img.float()\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(img.shape) == 3:\n",
    "        img = img[None]\n",
    "    t1 = time.time()\n",
    "    print(t1-t0)\n",
    "    with torch.no_grad():\n",
    "        pred = model[0](img, augment=False)[0]\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    \n",
    "    # Apply NMS        \n",
    "    pred = ops.non_max_suppression(pred, conf_thres, iou_thres, agnostic=False)\n",
    "    fake_result = {}\n",
    "    fake_result[\"algorithm_data\"] = {\n",
    "       \"is_alert\": False,\n",
    "       \"target_count\": 0,\n",
    "       \"target_info\": []\n",
    "   }\n",
    "    fake_result[\"model_data\"] = {\"objects\": []}\n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        # gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = ops.scale_boxes(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "            for *xyxy, conf, cls in det:\n",
    "                fake_result[\"model_data\"]['objects'].append({\n",
    "                    \"x\":int(xyxy[0]),\n",
    "                    \"y\":int(xyxy[1]),\n",
    "                    \"width\":int(xyxy[2]-xyxy[0]),\n",
    "                    \"height\":int(xyxy[3]-xyxy[1]),\n",
    "                    \"confidence\":float(conf),\n",
    "                    #\"name\":names[int(cls)]\n",
    "                    })\n",
    "                print(cls)\n",
    "    if args is not None and 'mask_output_path' in cfg.keys() and cfg['mask_output_path']:\n",
    "        fake_result[\"model_data\"][\"mask\"] = cfg['mask_output_path']\n",
    "        with torch.no_grad():\n",
    "            pred_seg = model[1](img, augment=False)\n",
    "        p = ops.non_max_suppression(pred_seg[0], conf_thres, iou_thres, agnostic=False, nm=32)\n",
    "        proto = pred_seg[1][-1]\n",
    "        for i, det in enumerate(p):  # detections per image\n",
    "            if det is not None and len(det):\n",
    "                det[:, :4] = ops.scale_boxes(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "                masks = ops.process_mask_native(proto[i], det[:, 6:], det[:, :4], img0.shape[:2])\n",
    "                masks = masks.cpu().numpy().astype(int)\n",
    "                for j in range(masks.shape[0]):\n",
    "                    if int(det[j][5]) == 2:\n",
    "                        masks[j][masks[j] == 1] = 2\n",
    "                if masks.shape[0] == 2:\n",
    "                    merged_mask = np.maximum.reduce([masks[0], masks[1]])\n",
    "                    cv2.imwrite(cfg['mask_output_path'], merged_mask)\n",
    "                else:\n",
    "                    cv2.imwrite(cfg['mask_output_path'], masks[0])\n",
    "\n",
    "    fake_result [\"algorithm_data\"][\"target_info\"]=[]\n",
    "    return json.dumps(fake_result, indent = 4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from glob import glob\n",
    "    # Test API\n",
    "    image_names = glob('/home/data/2783/*.jpg')\n",
    "    predictor = init()\n",
    "    s = 0\n",
    "    args = {\"mask_output_path\": \"mask_result.png\"}\n",
    "    #args = {\"mask_output_path\": ''}\n",
    "    args = json.dumps(args, indent = 4)\n",
    "        \n",
    "    for image_name in image_names:\n",
    "        print(image_name)\n",
    "        img = cv2.imread(image_name)\n",
    "        t1 = time.time()\n",
    "        res = process_image(predictor, img, args)\n",
    "        print(res)\n",
    "        t2 = time.time()\n",
    "        s += t2 - t1\n",
    "        break\n",
    "    print(1/(s/100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
